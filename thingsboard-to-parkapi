#! /usr/bin/env python3

import requests
import csv
import os
import operator
import datetime
import json
import sys
from argparse import ArgumentParser

CITY="herrenberg"

def get_attribute(items, name):
    for i in items:
        if(i["key"] == name):
            return i["value"]

def get_timeseries_value(timeseries, name):
    val = timeseries[name][0]["value"]
    if val == None:
        return 0
    else:
        return int(float(val))

def remove_special_chars(string):
    """
    Remove any umlauts, spaces and punctuation from a string.

    :param string:
    :return:
    """
    replacements = {
        "ä": "ae",
        "ö": "oe",
        "ü": "ue",
        "ß": "ss",
        "-": "",
        " ": "",
        ".": "",
        ",": "",
        "'": "",
        "+": "",
        "\"": "",
        "/": "",
        "\\": "",
        "\n": "",
        "\t": ""
    }
    for repl in replacements.keys():
        string = string.replace(repl, replacements[repl])
    return string


def fetch_dynamic_lot(base_url, auth_headers, id):

    print(f"Fetching information for lot {id}")
    
    try: 
        attribute_url = f"{base_url}/plugins/telemetry/ASSET/{id}/values/attributes?keys=address,latitude,longitude"
        attrs = requests.get(attribute_url, headers=auth_headers).json()

        timeseries_url = f"{base_url}/plugins/telemetry/ASSET/{id}/values/timeseries?keys=latestSumParkingState,SumOccupied,TotalParking_mapping,freeShortTermSpaces"
        timeseries = requests.get(timeseries_url, headers=auth_headers).json()
        total = get_timeseries_value(timeseries, "TotalParking_mapping")
        occupied = get_timeseries_value(timeseries, "latestSumParkingState")
        free = get_timeseries_value(timeseries, "freeShortTermSpaces") or total - occupied

        address = get_attribute(attrs, "address")
        return {
            "id":               id,
            "lot_type":         "Parkplatz",
            "address":          address,
            "name":             address,
            "forecast":         False,
            "state":            "open",
            "coords" : {
                "lat":          get_attribute(attrs, "latitude"),
                "lng":          get_attribute(attrs, "longitude"),
            },
            "total":            total,
            "free":             free,
        }
    except Exception as e:
        print(e)
        return {}

def fetch_dynamic_lots(static_lots):
    base_url = os.environ['THINGSBOARD_API_URL']

    token_url = f"{base_url}/auth/login"

    payload = {
        "username": os.environ['THINGSBOARD_USERNAME'],
        "password": os.environ['THINGSBOARD_PASSWORD']
    }

    response = requests.post(token_url, json=payload)
    token = response.json()["token"]

    auth_headers = {
        "X-Authorization": f"Bearer {token}"
    }
    ids = list(map(lambda lot : lot.get("id"), static_lots))
    # remove Nones (strange python syntax if you ask me)
    ids = list(filter(None, ids))

    disabled_ids = list(map(lambda lot : lot.get("id:disabled"), static_lots))
    # remove None
    disabled_ids = list(filter(None, disabled_ids))

    all_ids = ids + disabled_ids

    dynamic_lots = list(map(lambda id: fetch_dynamic_lot(base_url, auth_headers, id), all_ids))

    print(f"Fetched occupancy information for {len(dynamic_lots)} parking lots")

    return dynamic_lots

def clean_nones(value):
    """
    Recursively remove all None or empty string values from dictionaries and lists, and returns
    the result as a new dictionary or list.
    """
    if isinstance(value, list):
        return [clean_nones(x) for x in value if x is not None and x != '']
    elif isinstance(value, dict):
        return {
            key: clean_nones(val)
            for key, val in value.items()
            if val is not None and val != ''
        }
    else:
        return value

def fetch_static_lots_geojson(geojson_file):
    res = []
    with open(geojson_file, 'r', encoding='utf-8') as f:
        geojson = json.load(f)

        for lot in geojson["features"]:
            props = lot["properties"]
            coords = lot["geometry"]["coordinates"]
            l = {
                "id":               props.get("id"),
                "id:disabled":      props.get("id:disabled"),
                "lot_type":         props["type"],
                "address":          props["name"],
                "name":             props["name"],
                "forecast":         False,
                "state":            props.get("state", "nodata"),
                "coords" : {
                    "lat":          float(coords[1]),
                    "lng":          float(coords[0])
                },
                "total":            props.get("capacity"),
                "total:disabled": props.get("capacity:disabled"),

                "url":              props.get("url"),
                "fee_hours":        props.get("fee_hours"),
                "opening_hours":    props.get("opening_hours"),
                "notes":            props.get("notes")
            }

            res.append(clean_nones(l))

    return res

def fetch_static_lots_csv(csv_url):
    res = []
    with requests.get(csv_url, stream=True) as r:
        lines = (line.decode('utf-8') for line in r.iter_lines())
        reader = csv.DictReader(lines, delimiter=',')

        for lot in reader:
            l = {
                "id":               lot.get("id"),
                "id:disabled":      lot.get("id:disabled"),
                "lot_type":         lot.get("type"),
                "address":          lot.get("address"),
                "name":             lot.get("name"),
                "forecast":         False,
                "state":            lot.get("state") if lot.get("state") != '' else 'nodata',
                "coords" : {
                    "lat":          float(lot.get("lat")),
                    "lng":          float(lot.get("lon"))
                },
                "total":            int(lot.get("capacity")) if lot.get("capacity") != '' else None,
                "total:disabled":   int(lot.get("capacity:disabled")) if lot.get("capacity:disabled") != '' else None,

                "url":              lot.get("url"),
                "fee_hours":        lot.get("fee_hours"),
                "opening_hours":    lot.get("opening_hours"),
                "notes": {
                    "de": lot.get("notes:de"),
                    "en": lot.get("notes:en")
                }
            }

            res.append(clean_nones(l))

        return res

def merge_data(dynamic, static):
    for lot in static:
        id = lot.get("id")
        id_disabled = lot.get("id:disabled")

        if lot["state"] == "closed":
            pass
        elif id == None:
            lot["state"] = "nodata"
        else:
            dynamic_lots = [x for x in dynamic if x.get("id") == id]
            if len(dynamic_lots) > 0:
                dynamic_lot = dynamic_lots[0]

                free = dynamic_lot["free"]
                total = int(lot.get("total", lot.get("total:disabled")))

                if lot["lot_type"] == "Barrierefreier-Parkplatz":
                    lot["free:disabled"] = free
                else:
                    lot["free"] = free

                if free <= 0:
                    lot["state"] = "full"
                elif free/total < 0.05:
                    lot["state"] = "few"
                else:
                    lot["state"] = "many"

        # dealing with parking lots that have additional wheelchair parking
        # bays; here we just set the free:disabled property and are done
        if id_disabled != None:
            disabled_lots = [x for x in dynamic if x.get("id") == id_disabled]

            if len(disabled_lots) > 0:
                disabled_lot = disabled_lots[0]

                lot["free:disabled"] = disabled_lot["free"]

    return static

def write_parkapi(outfile, lots, data_source):
    utc_now = datetime.datetime.utcnow().isoformat()

    cnt = 0
    for lot in lots:
        cnt = cnt+1
        lot["id"] = CITY + remove_special_chars(lot.get('name', str(cnt)).lower())

    parken_api_response = {
        "data_source": data_source,
        "last_downloaded": utc_now,
        "last_updated": utc_now,
        "lots": lots
    }

    with open(outfile, 'w', encoding='utf-8') as f:
        json.dump(parken_api_response, f, ensure_ascii=False, indent=2)

    print(f"Wrote output to {outfile}")

if __name__ == '__main__':
    parser = ArgumentParser()

    parser.add_argument('--realtime', help="retrieve realtime infos from thingsboard", dest='realtime', action='store_true')
    parser.add_argument('--no-realtime', help="do not retrieve realtime infos from thingsboard", dest='realtime', action='store_false')
    parser.set_defaults(realtime=True)
    parser.add_argument("-o", "--output", help="write output to FILE", default="parkapi.json")
    parser.add_argument("-g", "--geojson", help="the static geojson input file", default="parking_lots.geojson")
    parser.add_argument("-c", "--csv", help="the static csv input file")
    parser.add_argument("-s", "--data_source", help="Data source cited in parkapi.json")

    args = parser.parse_args()

    if (args.csv):
        static_lots = fetch_static_lots_csv(args.csv)
    else:
        static_lots = fetch_static_lots_geojson(args.geojson)
    print(f"Fetched {len(static_lots)} static parking lots")

    if args.realtime:
        dynamic_lots = fetch_dynamic_lots(static_lots)
    else:
        dynamic_lots = {}
    

    write_parkapi(args.output, merge_data(dynamic_lots, static_lots), args.data_source)

